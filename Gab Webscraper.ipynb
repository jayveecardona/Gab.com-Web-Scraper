{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb07d26-1585-4075-96e1-1cba1db13907",
   "metadata": {},
   "source": [
    "# Gab.com Web Scraper Overview\n",
    "\n",
    "This Python script scrapes information from a Gab user profile and saves the data to a CSV file. The script uses the selenium package to load the Gab profile and scroll down to the bottom of the page, the BeautifulSoup package to parse the HTML of the loaded webpage, and the pandas package to save the extracted data into a CSV file.\n",
    "\n",
    "### Known bugs:\n",
    "1. At it's current state, some posts being extracted are skipped. Possible issues are that some posts do not have text in them and are simple reposts from other users.\n",
    "2. There are instances where the output would mismatch their associated engagement metrics, due to some line skipping.\n",
    "3. Even if there are an x number of posts found, not all of them are extracted again due to the issues mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bba4504-ac25-4b4c-a8b5-2c20423f90f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing packages needed for this web scraper\n",
    "\n",
    "The script imports the following Python libraries:\n",
    "1. **selenium** to use it's *webdriver* for scrolling to the bottom of the page, so we can load all posts from the user.\n",
    "2. **BeautifulSoup** for parsing through our saved html files and extracting the information we will be needing.\n",
    "3. **pandas** for converting our extracted data into a DataFrame, and outputting into a csv file.\n",
    "4. **time** is for using it's *sleep* function to add needed delays in our python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91fb055c-aac1-42f5-9960-474847e01525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver #To load all possible posts\n",
    "from bs4 import BeautifulSoup #To scrape information\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cbb8eb-38da-4af9-a451-e25ce120bca2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Here we initialize our automated instance of Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a470e8fe-b370-49ba-8972-4d078352f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=\"chromedriver_win32/chromedriver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec27261-8f01-4394-b59a-345ff037be12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Opening the Gab.com User Profile\n",
    "\n",
    "In this section, we first create the variable `gab_url` which asks for the user's input. For this, we will be needing the url of the desired Gab User.\n",
    "- Example: https://www.gab.com/a - This is the url of Gab's CEO\n",
    "\n",
    "The user's input is then stored and used for:\n",
    "- *webdriver* knowing which profile to open and save.\n",
    "- A variable called `filename` which will be used for difference usecases. e.g. HTML file names, CSV file names, foreign key for merging each post to the user's information, etc.\n",
    "\n",
    "This website is then opened by the automated Chrome instance, scrolled twice to make sure all posts are loaded, then saved as an html file with the profile's username as it's file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597767bd-1bf2-4dee-834e-1bb3d6313c76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " https://www.gab.com/a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gab User a.html saved!\n"
     ]
    }
   ],
   "source": [
    "# For user input of desired profile for web scraping\n",
    "gab_url = input()\n",
    "\n",
    "# Will be for different usecases\n",
    "filename = gab_url.split(\".com/\")[1]\n",
    "\n",
    "# Loading the gab_url input of user, scrolling down to max scrollable post\n",
    "driver.get(gab_url)\n",
    "driver.execute_script(\"window.scrollTo(1,10000)\")\n",
    "driver.execute_script(\"window.scrollTo(1,10000)\")\n",
    "\n",
    "# To give time for webpage to fully load\n",
    "time.sleep(20)\n",
    "\n",
    "# Saving the loaded website into an html file for scraping\n",
    "html = driver.page_source\n",
    "with open(\"gab/{}.html\".format(filename), \"w+\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "print(\"Gab User\", str(filename)+\".html saved!\", end=\"\\n\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989263ae-bdc3-4053-8d7b-3bd79661bca9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using BeautifulSoup\n",
    "\n",
    "Here's the fun part!\n",
    "\n",
    "Now that we have our HTML file, we will now use **BeautifulSoup** to parse that HTML file and extract the information that we need.\n",
    "\n",
    "For this project, I opted to extract the following:\n",
    "1. **Date Joined** - The time user joined/registered.\n",
    "2. **Username** - The profile's username.\n",
    "3. **Profile Photo** - The user's profile photo which will be in the form of a url.\n",
    "4. **Cover Photo** - The user's cover photo which also will be in the form of a url.\n",
    "5. **About** - The user's bio/about section in their profile.\n",
    "6. **Gabs** - This pertains to the number of posts they have. Can be likened to Twitter's Tweets.\n",
    "7. **Followers** - How many users follow the profile we chose.\n",
    "8. **Following** - How many users the profile we chose follows.\n",
    "9. **Posts** - Their posts, extracting the text contained within.\n",
    "10. **Post Media** - Media associated to their post, in the form of a url.\n",
    "11. **Reactions** - The number of reactions their post made.\n",
    "12. **Replies** - How many comments were made on their post.\n",
    "13. **Reposts** - How many reposts the post had.\n",
    "14. **Quotes** - How many posts were made where the post was quoted.\n",
    "\n",
    "### Exception Handling\n",
    "The script includes exception handling for cases where the profile, for example, does not have a cover photo, bio, and other use cases mentioned in the script. If the profile does not have them, the script assigns the value 'None' to the variables. This is also to avoid throwing an error wherein the specified `class ID` in our script is not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3daa5f92-7d70-4acc-bf74-dff8e0edd24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists for each field\n",
    "fields = ['Date Joined', 'Username', 'User Image', 'Cover Photo', 'About', 'Gabs', 'Followers', 'Following']\n",
    "date_joined = []\n",
    "user_name = []\n",
    "user_image = []\n",
    "cover_photo = []\n",
    "about = []\n",
    "number_of_gabs = []\n",
    "number_of_followers = []\n",
    "number_of_following = []\n",
    "\n",
    "# Now, we open the html file we just saved for parsing using BeautifulSoup package\n",
    "with open(\"gab/{}.html\".format(filename), encoding=\"utf-8\") as f:\n",
    "        page = f.read()\n",
    "\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "# Crosschecking variable for later\n",
    "NoneType = soup.find(\"img\", class_=\"xxxxxxxxxxx\")\n",
    "\n",
    "# Extracts when the member joined\n",
    "joined = soup.find(\"span\", class_=\"_33mR1 _UuSG _3_54N a8-QN _2cSLK L4pn5 RiX17\").text.split(\"since \")[1]\n",
    "\n",
    "# Extracts the username of the member\n",
    "name = soup.find(\"span\", class_=\"_3_54N _3rXHO _317eq _2xqBt _2z1u_ a8-QN L4pn5 grnpY _3tKl_\").text\n",
    "\n",
    "# Extracts the Profile Picture url\n",
    "# The if statement was included since there were different values in my experience\n",
    "userimage = soup.find(\"img\", width=\"88\")\n",
    "if type(userimage) == type(NoneType):\n",
    "    userimage = soup.find(\"img\", width=\"150\").attrs[\"src\"]\n",
    "else:\n",
    "    userimage = soup.find(\"img\", width=\"88\").attrs[\"src\"]\n",
    "\n",
    "# Extracts the Cover Photo url\n",
    "# The if statement was included to not throw an error on profiles with no cover photo\n",
    "coverphoto = soup.find(\"img\", alt=\"Header photo\", title=\"Header photo\")\n",
    "if type(coverphoto) == type(NoneType):\n",
    "    coverphoto = 'None'\n",
    "else:\n",
    "    coverphoto = soup.find(\"img\", alt=\"Header photo\", title=\"Header photo\").attrs[\"src\"]\n",
    "\n",
    "# Extracts the \"About\" section of the profile\n",
    "bio = soup.find(\"div\", class_=\"_9utbn\")\n",
    "if bio == NoneType:\n",
    "    bio = 'None'\n",
    "else:\n",
    "    bio = bio.text\n",
    "\n",
    "# Extracts the \"Gabs\" of the profile\n",
    "gabs = int(soup.find(\"a\", class_=\"_UuSG ALevz _3Ujf8 _1o5Ge _81_1w _3dGg1 _2mtbj _1AbQQ active\").attrs[\"title\"].split(\" Gabs\")[0].replace(\",\",\"\"))\n",
    "\n",
    "# Extracts the number of followers\n",
    "followers = int(soup.find(\"a\", class_=\"_UuSG ALevz _3Ujf8 _1o5Ge _81_1w _3dGg1 _2mtbj _1AbQQ\").attrs[\"title\"].split(\" Followers\")[0].replace(\",\",\"\"))\n",
    "\n",
    "# Extracts the number of users the profile follows\n",
    "following = int(soup.find(\"a\", class_=\"_UuSG ALevz _3Ujf8 _1o5Ge _81_1w _3dGg1 _2mtbj _1AbQQ\", href=\"/{}/following\".format(filename)).attrs[\"title\"].split(\" Following\")[0].replace(\",\",\"\"))\n",
    "\n",
    "# Extracted information are then appended to the lists created prior for later merging\n",
    "date_joined.append(joined)\n",
    "user_name.append(name)\n",
    "user_image.append(userimage)\n",
    "cover_photo.append(coverphoto)\n",
    "about.append(bio)\n",
    "number_of_gabs.append(gabs)\n",
    "number_of_followers.append(followers)\n",
    "number_of_following.append(following)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d7e94df-bd3f-44ed-bc25-db603bdeeac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All available posts are now extracted\n",
    "posts_soup = soup.find_all(\"div\", tabindex=\"0\", lang=\"en\")\n",
    "posts = []\n",
    "userpost = []\n",
    "\n",
    "# Each post is iterated and is put into a list for later merging\n",
    "for post in posts_soup:\n",
    "    posts.append(post.text)\n",
    "    userpost.append(\"@\"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de537b4d-e90a-4cb3-94f8-e71475868d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All available imageurls are now extracted from each post\n",
    "imageposts = soup.find_all(\"img\", loading=\"lazy\")\n",
    "media = []\n",
    "\n",
    "# Each imageurl is iterated and is pute into a list for later merging\n",
    "for link in imageposts:\n",
    "    media.append(link.attrs[\"src\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84cbfb96-c8f1-436a-ae01-182cdbf352c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we create the \"epp\" variable for iterating the lists created\n",
    "epp = soup.find_all(\"div\", class_=\"_UuSG _3dGg1 _2VJFi SslQJ _2pVfg\")\n",
    "reactions = []\n",
    "replies = []\n",
    "reposts = []\n",
    "quotes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd221f43-0cf9-4847-a484-3927ceb54992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following for loops iterate on \"epp\" to get the number of reactions, replies, reposts, and quotes for each post.\n",
    "# If else statements are included to take into consideration that some of them may be in the thousands, where Gab summarizes them.\n",
    "# Also, getting the number of \"quotes\" can be tricky since replies and quotes have the same class id.\n",
    "# That's where multiple if statements were used to prevent capturing the wrong data\n",
    "\n",
    "for engagement in epp:\n",
    "    reaction = engagement.find(\"span\", class_=\"_3u7ZG _UuSG _3_54N a8-QN _2cSLK L4pn5 RiX17\")\n",
    "    if reaction == NoneType:\n",
    "        reaction = int(0)\n",
    "    else:\n",
    "        reaction = reaction.text.split(\"k\")[0]\n",
    "        if \".\" in reaction:\n",
    "            reaction = int(float(reaction) * 1000)\n",
    "        else:\n",
    "            reaction = int(reaction)\n",
    "    reactions.append(reaction)\n",
    "\n",
    "for engagement in epp:\n",
    "    reply = engagement.find(\"span\", class_=\"_UuSG _3_54N a8-QN _2cSLK L4pn5 RiX17\")\n",
    "    if reply == NoneType:\n",
    "        reply = int(0)\n",
    "    else:\n",
    "        reply = reply.text.split(\" repl\")[0]\n",
    "        if \"repost\" in reply:\n",
    "            reply = int(0)\n",
    "        else:\n",
    "            reply = reply.split(\"k\")[0]\n",
    "            if \".\" in reply:\n",
    "                reply = int(float(reply) * 1000)\n",
    "            else:\n",
    "                reply = int(reply)\n",
    "    replies.append(reply)\n",
    "    \n",
    "for engagement in epp:\n",
    "    repost = engagement.find(\"button\", class_=\"_UuSG _3_54N L4pn5 _3Ujf8 _1o5Ge _81_1w _3TwRa _3OtSI ALevz A0UHB\")\n",
    "    if repost == NoneType:\n",
    "        repost = int(0)\n",
    "    else:\n",
    "        repost = repost.text.split(\" repost\")[0].split(\"k\")[0]\n",
    "        if \".\" in repost:\n",
    "            repost = int(float(repost) * 1000)\n",
    "        else:\n",
    "            repost = int(repost)\n",
    "    reposts.append(repost)\n",
    "    \n",
    "for engagement in epp:\n",
    "    quote = engagement.find(\"button\", class_=\"_UuSG _3_54N L4pn5 _3Ujf8 _1o5Ge _81_1w _3TwRa _3OtSI ALevz A0UHB\")\n",
    "    if quote == NoneType:\n",
    "        quote = int(0)\n",
    "    elif quote.find_next_sibling(\"button\") == NoneType:\n",
    "        quote = int(0)\n",
    "    else:\n",
    "        quote = quote.find_next_sibling(\"button\").text.split(\" quote\")[0].split(\"k\")[0]\n",
    "        if \".\" in quote:\n",
    "            quote = int(float(quote) * 1000)\n",
    "        else:\n",
    "            quote = int(quote)\n",
    "    quotes.append(quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce31000-42ef-4c05-a282-6b4ff23684ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Saving the Extracted Data using pandas\n",
    "\n",
    "The extracted data is saved to a CSV file using the **pandas** package. The **pd.DataFrame()** function is used to create a DataFrame from the lists containing the extracted data. The DataFrame is then saved to a CSV file using the **to_csv()** function with the **index=False** argument to exclude the index column from the CSV file.\n",
    "\n",
    "In addition to our extracted data, we also added:\n",
    "1. **Total Engagement** - This is the total of adding each post's Reactions, Replies, Reposts, and Quotes.\n",
    "2. **Avg Engagement** - This uses `Total Engagement` and divides the number by 4 to get this metric.\n",
    "3. **Avg Post Engagement** - This metric is calculated by getting the total of all post engagements and dividing it by the number of posts we have extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd7ba8c0-3886-4ffe-940d-13146fa3d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas DataFrames are now created for both user information and user posts information.\n",
    "# The Total Engagement column and Avg Engagement Column were also added based on the merge information for posts.\n",
    "# An Avg Post Engagement column was also added in the user information to show the average engagement per post the user gets\n",
    "\n",
    "dfposts = pd.DataFrame(data = zip(userpost, posts, media, reactions, replies, reposts, quotes), columns = ['Username', 'Post', 'Media', 'Reactions', 'Replies', 'Reposts', 'Quotes'])\n",
    "dfposts['Total Engagement'] = dfposts.Reactions + dfposts.Replies + dfposts.Reposts + dfposts.Quotes\n",
    "dfposts['Avg Engagement'] = dfposts['Total Engagement']/4\n",
    "dfposts['Avg Engagement'].round(2)\n",
    "\n",
    "dfuser = pd.DataFrame(data = zip(date_joined, user_name, user_image, cover_photo, about, number_of_gabs, number_of_followers, number_of_following), columns = fields)\n",
    "dfuser['Avg Post Engagement'] = dfposts['Total Engagement'].sum()/len(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c11d0c2-2ca1-4321-aa5a-5210134e1e32",
   "metadata": {},
   "source": [
    "### Now let's look at our extracted data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c4ef8a2-9fd8-44fa-8271-a00f8904e307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Post</th>\n",
       "      <th>Media</th>\n",
       "      <th>Reactions</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Reposts</th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Total Engagement</th>\n",
       "      <th>Avg Engagement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@a</td>\n",
       "      <td>\"In a September 2022 audit of the seven sites ...</td>\n",
       "      <td>https://media.gab.com/cdn-cgi/image/width=410,...</td>\n",
       "      <td>1200</td>\n",
       "      <td>180</td>\n",
       "      <td>255</td>\n",
       "      <td>19</td>\n",
       "      <td>1654</td>\n",
       "      <td>413.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@a</td>\n",
       "      <td>Gab is a First Amendment company which means w...</td>\n",
       "      <td>https://media.gab.com/cdn-cgi/image/width=420,...</td>\n",
       "      <td>4</td>\n",
       "      <td>439</td>\n",
       "      <td>1100</td>\n",
       "      <td>47</td>\n",
       "      <td>1590</td>\n",
       "      <td>397.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@a</td>\n",
       "      <td>Just some of my Original, Miniature, wearable ...</td>\n",
       "      <td>https://media.gab.com/cdn-cgi/image/width=420,...</td>\n",
       "      <td>17100</td>\n",
       "      <td>3400</td>\n",
       "      <td>4300</td>\n",
       "      <td>199</td>\n",
       "      <td>24999</td>\n",
       "      <td>6249.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@a</td>\n",
       "      <td>Proverbs 22:6 Train up a child in the way he s...</td>\n",
       "      <td>https://media.gab.com/system/media_attachments...</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@a</td>\n",
       "      <td>Serenity of Stillness…</td>\n",
       "      <td>https://media.gab.com/cdn-cgi/image/width=420,...</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>22.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Username                                               Post  \\\n",
       "0       @a  \"In a September 2022 audit of the seven sites ...   \n",
       "1       @a  Gab is a First Amendment company which means w...   \n",
       "2       @a  Just some of my Original, Miniature, wearable ...   \n",
       "3       @a  Proverbs 22:6 Train up a child in the way he s...   \n",
       "4       @a                             Serenity of Stillness…   \n",
       "\n",
       "                                               Media  Reactions  Replies  \\\n",
       "0  https://media.gab.com/cdn-cgi/image/width=410,...       1200      180   \n",
       "1  https://media.gab.com/cdn-cgi/image/width=420,...          4      439   \n",
       "2  https://media.gab.com/cdn-cgi/image/width=420,...      17100     3400   \n",
       "3  https://media.gab.com/system/media_attachments...         45        6   \n",
       "4  https://media.gab.com/cdn-cgi/image/width=420,...         80        4   \n",
       "\n",
       "   Reposts  Quotes  Total Engagement  Avg Engagement  \n",
       "0      255      19              1654          413.50  \n",
       "1     1100      47              1590          397.50  \n",
       "2     4300     199             24999         6249.75  \n",
       "3        9       0                60           15.00  \n",
       "4        7       0                91           22.75  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfposts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c60e210d-be7f-4cf3-a683-15b0e7e9430e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Joined</th>\n",
       "      <th>Username</th>\n",
       "      <th>User Image</th>\n",
       "      <th>Cover Photo</th>\n",
       "      <th>About</th>\n",
       "      <th>Gabs</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Following</th>\n",
       "      <th>Avg Post Engagement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>August 2016</td>\n",
       "      <td>@a</td>\n",
       "      <td>https://media.gab.com/system/accounts/avatars/...</td>\n",
       "      <td>https://media.gab.com/system/accounts/headers/...</td>\n",
       "      <td>Saved servant soldier of Jesus Christ. Husband...</td>\n",
       "      <td>69270</td>\n",
       "      <td>3878881</td>\n",
       "      <td>2745</td>\n",
       "      <td>1962.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date Joined Username                                         User Image  \\\n",
       "0  August 2016       @a  https://media.gab.com/system/accounts/avatars/...   \n",
       "\n",
       "                                         Cover Photo  \\\n",
       "0  https://media.gab.com/system/accounts/headers/...   \n",
       "\n",
       "                                               About   Gabs  Followers  \\\n",
       "0  Saved servant soldier of Jesus Christ. Husband...  69270    3878881   \n",
       "\n",
       "   Following  Avg Post Engagement  \n",
       "0       2745             1962.625  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfuser.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017fac11-99b9-4e88-8c25-6f58a4d3a2d3",
   "metadata": {},
   "source": [
    "### Finally, let's save all of that into one csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4de6d5c2-3ac2-4fc5-a3a1-8dd495d0518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframes are then merged and saved into one csv file for further use and/or analysis.\n",
    "\n",
    "df = pd.merge(dfuser, dfposts, on='Username').to_csv(\"gab/{}.csv\".format(filename), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
